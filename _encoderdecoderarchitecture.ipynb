{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jainmridul82/Encoder-Decoder-Architecture/blob/main/_encoderdecoderarchitecture.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h02pEMJXG8PO"
      },
      "source": [
        "## Outline\n",
        "\n",
        "\n",
        "1. Data set and task\n",
        "2. Data processing XML files\n",
        "3. Why we need encoder decoder architecture\n",
        "4. Basic GRU based encoder decoder\n",
        "5. Adding attention\n",
        "6. Evaluation\n",
        "7. Exercises"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36lfNrOIG-JH"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "\n",
        "# Instantiates the device to be used as GPU/CPU based on availability\n",
        "device_gpu = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Visualization tools\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from IPython.display import clear_output\n",
        "\n",
        "import random"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Zhl3PaoHAcC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "b3e656b9-8067-4797-aaf9-8b4aa141eb8f"
      },
      "source": [
        "eng_alphabets = 'ABCDEFGHIJKLMNOPQRSTUVWXYZ'\n",
        "pad_char = '-PAD-'\n",
        "\n",
        "eng_alpha2index = {pad_char: 0}\n",
        "for index, alpha in enumerate(eng_alphabets):\n",
        "    eng_alpha2index[alpha] = index+1\n",
        "\n",
        "print(eng_alpha2index)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'-PAD-': 0, 'A': 1, 'B': 2, 'C': 3, 'D': 4, 'E': 5, 'F': 6, 'G': 7, 'H': 8, 'I': 9, 'J': 10, 'K': 11, 'L': 12, 'M': 13, 'N': 14, 'O': 15, 'P': 16, 'Q': 17, 'R': 18, 'S': 19, 'T': 20, 'U': 21, 'V': 22, 'W': 23, 'X': 24, 'Y': 25, 'Z': 26}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nl0vwMpeHNJx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "4cc246dc-fc03-4c9c-f7e0-d3f6454081f1"
      },
      "source": [
        "# Hindi Unicode Hex Range is 2304:2432. Source: https://en.wikipedia.org/wiki/Devanagari_(Unicode_block)\n",
        "\n",
        "hindi_alphabets = [chr(alpha) for alpha in range(2304, 2432)]\n",
        "hindi_alphabet_size = len(hindi_alphabets)\n",
        "\n",
        "hindi_alpha2index = {pad_char: 0}\n",
        "for index, alpha in enumerate(hindi_alphabets):\n",
        "    hindi_alpha2index[alpha] = index+1\n",
        "\n",
        "print(hindi_alpha2index)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'-PAD-': 0, 'ऀ': 1, 'ँ': 2, 'ं': 3, 'ः': 4, 'ऄ': 5, 'अ': 6, 'आ': 7, 'इ': 8, 'ई': 9, 'उ': 10, 'ऊ': 11, 'ऋ': 12, 'ऌ': 13, 'ऍ': 14, 'ऎ': 15, 'ए': 16, 'ऐ': 17, 'ऑ': 18, 'ऒ': 19, 'ओ': 20, 'औ': 21, 'क': 22, 'ख': 23, 'ग': 24, 'घ': 25, 'ङ': 26, 'च': 27, 'छ': 28, 'ज': 29, 'झ': 30, 'ञ': 31, 'ट': 32, 'ठ': 33, 'ड': 34, 'ढ': 35, 'ण': 36, 'त': 37, 'थ': 38, 'द': 39, 'ध': 40, 'न': 41, 'ऩ': 42, 'प': 43, 'फ': 44, 'ब': 45, 'भ': 46, 'म': 47, 'य': 48, 'र': 49, 'ऱ': 50, 'ल': 51, 'ळ': 52, 'ऴ': 53, 'व': 54, 'श': 55, 'ष': 56, 'स': 57, 'ह': 58, 'ऺ': 59, 'ऻ': 60, '़': 61, 'ऽ': 62, 'ा': 63, 'ि': 64, 'ी': 65, 'ु': 66, 'ू': 67, 'ृ': 68, 'ॄ': 69, 'ॅ': 70, 'ॆ': 71, 'े': 72, 'ै': 73, 'ॉ': 74, 'ॊ': 75, 'ो': 76, 'ौ': 77, '्': 78, 'ॎ': 79, 'ॏ': 80, 'ॐ': 81, '॑': 82, '॒': 83, '॓': 84, '॔': 85, 'ॕ': 86, 'ॖ': 87, 'ॗ': 88, 'क़': 89, 'ख़': 90, 'ग़': 91, 'ज़': 92, 'ड़': 93, 'ढ़': 94, 'फ़': 95, 'य़': 96, 'ॠ': 97, 'ॡ': 98, 'ॢ': 99, 'ॣ': 100, '।': 101, '॥': 102, '०': 103, '१': 104, '२': 105, '३': 106, '४': 107, '५': 108, '६': 109, '७': 110, '८': 111, '९': 112, '॰': 113, 'ॱ': 114, 'ॲ': 115, 'ॳ': 116, 'ॴ': 117, 'ॵ': 118, 'ॶ': 119, 'ॷ': 120, 'ॸ': 121, 'ॹ': 122, 'ॺ': 123, 'ॻ': 124, 'ॼ': 125, 'ॽ': 126, 'ॾ': 127, 'ॿ': 128}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZRqMtiSUHO87"
      },
      "source": [
        "import re\n",
        "non_eng_letters_regex = re.compile('[^a-zA-Z ]')\n",
        "\n",
        "# Remove all English non-letters\n",
        "def cleanEnglishVocab(line):\n",
        "    line = line.replace('-', ' ').replace(',', ' ').upper()\n",
        "    line = non_eng_letters_regex.sub('', line)\n",
        "    return line.split()\n",
        "\n",
        "# Remove all Hindi non-letters\n",
        "def cleanHindiVocab(line):\n",
        "    line = line.replace('-', ' ').replace(',', ' ')\n",
        "    cleaned_line = ''\n",
        "    for char in line:\n",
        "        if char in hindi_alpha2index or char == ' ':\n",
        "            cleaned_line += char\n",
        "    return cleaned_line.split()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JX_2jW_5HQ5w"
      },
      "source": [
        "from torch.utils.data import Dataset\n",
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "class TransliterationDataLoader(Dataset):\n",
        "    def __init__(self, filename):\n",
        "        self.eng_words, self.hindi_words = self.readXmlDataset(filename, cleanHindiVocab)\n",
        "        self.shuffle_indices = list(range(len(self.eng_words)))\n",
        "        random.shuffle(self.shuffle_indices)\n",
        "        self.shuffle_start_index = 0\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.eng_words)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.eng_words[idx], self.hindi_words[idx]\n",
        "\n",
        "    def readXmlDataset(self, filename, lang_vocab_cleaner):\n",
        "        transliterationCorpus = ET.parse(filename).getroot()\n",
        "        lang1_words = []\n",
        "        lang2_words = []\n",
        "\n",
        "        for line in transliterationCorpus:\n",
        "            wordlist1 = cleanEnglishVocab(line[0].text)\n",
        "            wordlist2 = lang_vocab_cleaner(line[1].text)\n",
        "\n",
        "            # Skip noisy data\n",
        "            if len(wordlist1) != len(wordlist2):\n",
        "                print('Skipping: ', line[0].text, ' - ', line[1].text)\n",
        "                continue\n",
        "\n",
        "            for word in wordlist1:\n",
        "                lang1_words.append(word)\n",
        "            for word in wordlist2:\n",
        "                lang2_words.append(word)\n",
        "\n",
        "        return lang1_words, lang2_words\n",
        "\n",
        "    def get_random_sample(self):\n",
        "        return self.__getitem__(np.random.randint(len(self.eng_words)))\n",
        "\n",
        "    def get_batch_from_array(self, batch_size, array):\n",
        "        end = self.shuffle_start_index + batch_size\n",
        "        batch = []\n",
        "        if end >= len(self.eng_words):\n",
        "            batch = [array[i] for i in self.shuffle_indices[0:end%len(self.eng_words)]]\n",
        "            end = len(self.eng_words)\n",
        "        return batch + [array[i] for i in self.shuffle_indices[self.shuffle_start_index : end]]\n",
        "\n",
        "    def get_batch(self, batch_size, postprocess = True):\n",
        "        eng_batch = self.get_batch_from_array(batch_size, self.eng_words)\n",
        "        hindi_batch = self.get_batch_from_array(batch_size, self.hindi_words)\n",
        "        self.shuffle_start_index += batch_size + 1\n",
        "\n",
        "        # Reshuffle if 1 epoch is complete\n",
        "        if self.shuffle_start_index >= len(self.eng_words):\n",
        "            random.shuffle(self.shuffle_indices)\n",
        "            self.shuffle_start_index = 0\n",
        "\n",
        "        return eng_batch, hindi_batch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DtJwlMRuHSqk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        },
        "outputId": "0137ee09-ddec-4f12-ed8c-643e0888f383"
      },
      "source": [
        "train_data = TransliterationDataLoader('/content/rI58TOlAScioEuPBbOYh_NEWS2012TrainingEnHi13937-1563719470862.xml')\n",
        "test_data = TransliterationDataLoader('/content/njThAK0RQGeoOuE9rfwg_NEWS2012RefEnHi1000-1563719263404.xml')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Skipping:  BARHARWA JUNCTION  -  बरहरवा\n",
            "Skipping:  STATE BNK TR  -  स्टेट बैंक ऑफ त्रावणकोर\n",
            "Skipping:  SOUTH ARLINGTON CHURCH OF CHRIST  -  साउथ अर्लिंग्टन\n",
            "Skipping:  KING EDWARD VII  -  किंग एडवर्ड\n",
            "Skipping:  DIBANG VALLEY  -  दिबंगवैली\n",
            "Skipping:  ORDER OF VASA  -  ऑडर ऑफ़ द वासा\n",
            "Skipping:  AZAMNAGAR ROAD  -  आज़मनगर\n",
            "Skipping:  CAPE TOWN  -  केपटाउन\n",
            "Skipping:  NEW ZEALAND  -  न्यूज़ीलैंड\n",
            "Skipping:  SEA OF THE HEBRIDES  -  सी ऑफ हरब्रिड्‍स\n",
            "Skipping:  RAMCOIND  -  राम्को इंड\n",
            "Skipping:  KELVINGROVE ART GALLERY AND MUSEUM  -  केल्व‍िनग्रोव आर्ट एण्ड म्युज़ियम\n",
            "Skipping:  AUSTRALIAN NATIONAL UNIVERSITY  -  ऑस्ट्रेलियननेशनल यूनिवर्सिटी\n",
            "Skipping:  JAHAN AARA  -  जहाँआरा\n",
            "Skipping:  NAVABHARAT FERRO ALLOYS  -  नव भारत फ़ैरो अलॉय\n",
            "Skipping:  RAMA LINGESHWARA  -  रामालिंगेश्वर\n",
            "Skipping:  FAKHRUN NISA  -  फखरुन्निसा\n",
            "Skipping:  REDIFF.COM INDIA LIMITED  -  रेडिफ़ डॉट कॉम इंडिया लिमिटेड\n",
            "Skipping:  OMKARNATH THAKUR  -  ओंकार नाथ ठाकुर\n",
            "Skipping:  OPENTV  -  ओपन टीवी\n",
            "Skipping:  ENVOY COMMUNICATIONS GROUP  -  एन्वॉय कम्युनिकेशंस\n",
            "Skipping:  WAR OF THE HOLY LEAGUE  -  वार ऑफ होली लीग\n",
            "Skipping:  VAPARAISO CHURCH OF CHRIST  -  व्हापरासिओ\n",
            "Skipping:  PARIS CHARLES DE GAULLE  -  पेरिस रॉसे चार्ल्स डे ग्यूले\n",
            "Skipping:  PARKWAY APOSTOLIC  -  पार्क वे अपोस्टोलिक\n",
            "Skipping:  MAUNA LOA  -  मौनालोआ\n",
            "Skipping:  MASS MUTUAL LIFE  -  मास म्युच्युअल लाइफ़ इंश्योरेंस\n",
            "Skipping:  STATS CHIPPAC  -  स्टेट्सचिपपैक\n",
            "Skipping:  NEWFOUNDLAND  -  न्यू फाउंडलैंड\n",
            "Skipping:  LONDONHEATHROW  -  लंदन हीथ्रो\n",
            "Skipping:  RETALIX  -  रेटालिक्स लि.\n",
            "Skipping:  SRISAILAM  -  श्री शैलम\n",
            "Skipping:  KARA-KUM  -  काराकुम\n",
            "Skipping:  WIND RIVER  -  विंडरिवर\n",
            "Skipping:  NETAJI SUBHASH CHANDRA BOSE  -  नेताजी सुभाषचंद्र बोस\n",
            "Skipping:  ROCKBROOK UNITED  -  रॉकब्रुक यूनाइटेड मेथोडिस्ट\n",
            "Skipping:  WALTER SCOTT  -  वॉल्टरस्कॉट\n",
            "Skipping:  COLOURPLUS FASHIONS  -  कलर प्लस फ़ैशन्स\n",
            "Skipping:  BAL KRISHNA  -  बालकृष्णा\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "umhapv7fHU0J",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "9fc15126-8213-4387-cb60-7d2e2a04454e"
      },
      "source": [
        "print(\"Train Set Size:\\t\", len(train_data))\n",
        "print(\"Test Set Size:\\t\", len(test_data))\n",
        "\n",
        "print('\\nSample data from train-set:')\n",
        "for i in range(10):\n",
        "    eng, hindi = train_data.get_random_sample()\n",
        "    print(eng + ' - ' + hindi)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Set Size:\t 20543\n",
            "Test Set Size:\t 1000\n",
            "\n",
            "Sample data from train-set:\n",
            "SALIMA - सलीमा\n",
            "TOMAI - टोमेई\n",
            "AUSTRALIAN - ऑस्ट्रेलियन\n",
            "GUJ - गुजरात\n",
            "GUGLANI - गुगलानी\n",
            "STUDIO - स्टुडियो\n",
            "VIPIN - विपिन\n",
            "JUPITER - ज्युपिटर\n",
            "NATURAL - नैचरल\n",
            "SCHOOL - स्कूल\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-hvXWxL7HeD8"
      },
      "source": [
        "def word_rep(word, letter2index, device = 'cpu'):\n",
        "    rep = torch.zeros(len(word)+1, 1, len(letter2index)).to(device)\n",
        "    for letter_index, letter in enumerate(word):\n",
        "        pos = letter2index[letter]\n",
        "        rep[letter_index][0][pos] = 1\n",
        "    pad_pos = letter2index[pad_char]\n",
        "    rep[letter_index+1][0][pad_pos] = 1\n",
        "    return rep\n",
        "\n",
        "def gt_rep(word, letter2index, device = 'cpu'):\n",
        "    gt_rep = torch.zeros([len(word)+1, 1], dtype=torch.long).to(device)\n",
        "    for letter_index, letter in enumerate(word):\n",
        "        pos = letter2index[letter]\n",
        "        gt_rep[letter_index][0] = pos\n",
        "    gt_rep[letter_index+1][0] = letter2index[pad_char]\n",
        "    return gt_rep"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tsWJQiFMHgC9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "38844634-6c13-486e-bce0-aa4db2b6702c"
      },
      "source": [
        "eng, hindi = train_data.get_random_sample()\n",
        "eng_rep = word_rep(eng, eng_alpha2index)\n",
        "print(eng, eng_rep)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WALL tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lWNyy2RmHhtJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "5524d268-08e7-4d8c-c916-d2ae94cbca95"
      },
      "source": [
        "hindi_gt = gt_rep(hindi, hindi_alpha2index)\n",
        "print(hindi, hindi_gt)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "वाल tensor([[54],\n",
            "        [63],\n",
            "        [51],\n",
            "        [ 0]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sfzHxTSsHjff"
      },
      "source": [
        "MAX_OUTPUT_CHARS = 30\n",
        "class Transliteration_EncoderDecoder(nn.Module):\n",
        "\n",
        "    def __init__(self, input_size, hidden_size, output_size, verbose=False):\n",
        "        super(Transliteration_EncoderDecoder, self).__init__()\n",
        "\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "\n",
        "        self.encoder_rnn_cell = nn.GRU(input_size, hidden_size)\n",
        "        self.decoder_rnn_cell = nn.GRU(output_size, hidden_size)\n",
        "\n",
        "        self.h2o = nn.Linear(hidden_size, output_size)\n",
        "        self.softmax = nn.LogSoftmax(dim=2)\n",
        "\n",
        "        self.verbose = verbose\n",
        "\n",
        "    def forward(self, input, max_output_chars = MAX_OUTPUT_CHARS, device = 'cpu', ground_truth = None):\n",
        "\n",
        "        # encoder\n",
        "        out, hidden = self.encoder_rnn_cell(input)\n",
        "\n",
        "        if self.verbose:\n",
        "            print('Encoder input', input.shape)\n",
        "            print('Encoder output', out.shape)\n",
        "            print('Encoder hidden', hidden.shape)\n",
        "\n",
        "        # decoder\n",
        "        decoder_state = hidden\n",
        "        decoder_input = torch.zeros(1, 1, self.output_size).to(device)\n",
        "        outputs = []\n",
        "\n",
        "        if self.verbose:\n",
        "            print('Decoder state', decoder_state.shape)\n",
        "            print('Decoder input', decoder_input.shape)\n",
        "\n",
        "        for i in range(max_output_chars):\n",
        "\n",
        "            out, decoder_state = self.decoder_rnn_cell(decoder_input, decoder_state)\n",
        "\n",
        "            if self.verbose:\n",
        "                print('Decoder intermediate output', out.shape)\n",
        "\n",
        "            out = self.h2o(decoder_state)\n",
        "            out = self.softmax(out)\n",
        "            outputs.append(out.view(1, -1))\n",
        "\n",
        "            if self.verbose:\n",
        "                print('Decoder output', out.shape)\n",
        "                self.verbose = False\n",
        "\n",
        "            max_idx = torch.argmax(out, 2, keepdim=True)\n",
        "            if not ground_truth is None:\n",
        "                max_idx = ground_truth[i].reshape(1, 1, 1)\n",
        "            one_hot = torch.FloatTensor(out.shape).to(device)\n",
        "            one_hot.zero_()\n",
        "            one_hot.scatter_(2, max_idx, 1)\n",
        "\n",
        "            decoder_input = one_hot.detach()\n",
        "\n",
        "        return outputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bUFhcTAzHlF-"
      },
      "source": [
        "net = Transliteration_EncoderDecoder(len(eng_alpha2index), 256, len(hindi_alpha2index), verbose=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CBJbBnYkHvGz"
      },
      "source": [
        "def infer(net,input_,max_output_chars,device='cpu'):\n",
        "  net=net.to(device)\n",
        "  input_=word_rep(input_,eng_alpha2index,device)\n",
        "  out=net(input_,max_output_chars,device,None)\n",
        "  return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m8UzoYnOHoju",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "e634190e-5215-469c-8237-a01568296932"
      },
      "source": [
        "out = infer(net, 'INDIA', 30)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Encoder input torch.Size([6, 1, 27])\n",
            "Encoder output torch.Size([6, 1, 256])\n",
            "Encoder hidden torch.Size([1, 1, 256])\n",
            "Decoder state torch.Size([1, 1, 256])\n",
            "Decoder input torch.Size([1, 1, 129])\n",
            "Decoder intermediate output torch.Size([1, 1, 256])\n",
            "Decoder output torch.Size([1, 1, 129])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLCldZsUHqFS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        },
        "outputId": "5fbada7c-be5b-4738-dcd1-325784bf069b"
      },
      "source": [
        "print(len(out))\n",
        "for i in range(len(out)):\n",
        "    print(out[i].shape, list(hindi_alpha2index.keys())[list(hindi_alpha2index.values()).index(torch.argmax(out[i]))])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "30\n",
            "torch.Size([1, 129]) ग़\n",
            "torch.Size([1, 129]) ॱ\n",
            "torch.Size([1, 129]) ॼ\n",
            "torch.Size([1, 129]) ॼ\n",
            "torch.Size([1, 129]) ॼ\n",
            "torch.Size([1, 129]) ऺ\n",
            "torch.Size([1, 129]) ॼ\n",
            "torch.Size([1, 129]) ॼ\n",
            "torch.Size([1, 129]) ॼ\n",
            "torch.Size([1, 129]) ऺ\n",
            "torch.Size([1, 129]) ॼ\n",
            "torch.Size([1, 129]) ॼ\n",
            "torch.Size([1, 129]) ऺ\n",
            "torch.Size([1, 129]) ॼ\n",
            "torch.Size([1, 129]) ॼ\n",
            "torch.Size([1, 129]) ॼ\n",
            "torch.Size([1, 129]) ऺ\n",
            "torch.Size([1, 129]) ॼ\n",
            "torch.Size([1, 129]) ॼ\n",
            "torch.Size([1, 129]) ऺ\n",
            "torch.Size([1, 129]) ॼ\n",
            "torch.Size([1, 129]) ॼ\n",
            "torch.Size([1, 129]) ॼ\n",
            "torch.Size([1, 129]) ऺ\n",
            "torch.Size([1, 129]) ॼ\n",
            "torch.Size([1, 129]) ॼ\n",
            "torch.Size([1, 129]) ऺ\n",
            "torch.Size([1, 129]) ॼ\n",
            "torch.Size([1, 129]) ॼ\n",
            "torch.Size([1, 129]) ॼ\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rvS3QPP0H3fw"
      },
      "source": [
        "class Transliteration_EncoderDecoder_Attention(nn.Module):\n",
        "\n",
        "    def __init__(self, input_size, hidden_size, output_size, verbose=False):\n",
        "        super(Transliteration_EncoderDecoder_Attention, self).__init__()\n",
        "\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "\n",
        "        self.encoder_rnn_cell = nn.GRU(input_size, hidden_size)\n",
        "        self.decoder_rnn_cell = nn.GRU(hidden_size*2, hidden_size)\n",
        "\n",
        "        self.h2o = nn.Linear(hidden_size, output_size)\n",
        "        self.softmax = nn.LogSoftmax(dim=2)\n",
        "\n",
        "        self.U = nn.Linear(self.hidden_size, self.hidden_size)\n",
        "        self.W = nn.Linear(self.hidden_size, self.hidden_size)\n",
        "        self.attn = nn.Linear(self.hidden_size, 1)\n",
        "        self.out2hidden = nn.Linear(self.output_size, self.hidden_size)\n",
        "\n",
        "        self.verbose = verbose\n",
        "\n",
        "    def forward(self, input, max_output_chars = MAX_OUTPUT_CHARS, device = 'cpu', ground_truth = None):\n",
        "\n",
        "        # encoder\n",
        "        encoder_outputs, hidden = self.encoder_rnn_cell(input)\n",
        "        encoder_outputs = encoder_outputs.view(-1, self.hidden_size)\n",
        "\n",
        "        if self.verbose:\n",
        "            print('Encoder output', encoder_outputs.shape)\n",
        "\n",
        "        # decoder\n",
        "        decoder_state = hidden\n",
        "        decoder_input = torch.zeros(1, 1, self.output_size).to(device)\n",
        "\n",
        "        outputs = []\n",
        "        U = self.U(encoder_outputs)\n",
        "\n",
        "        if self.verbose:\n",
        "            print('Decoder state', decoder_state.shape)\n",
        "            print('Decoder intermediate input', decoder_input.shape)\n",
        "            print('U * Encoder output', U.shape)\n",
        "\n",
        "        for i in range(max_output_chars):\n",
        "\n",
        "            W = self.W(decoder_state.view(1, -1).repeat(encoder_outputs.shape[0], 1))\n",
        "            V = self.attn(torch.tanh(U + W))\n",
        "            attn_weights = F.softmax(V.view(1, -1), dim = 1)\n",
        "\n",
        "            if self.verbose:\n",
        "                print('W * Decoder state', W.shape)\n",
        "                print('V', V.shape)\n",
        "                print('Attn', attn_weights.shape)\n",
        "\n",
        "            attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
        "                                 encoder_outputs.unsqueeze(0))\n",
        "\n",
        "            embedding = self.out2hidden(decoder_input)\n",
        "            decoder_input = torch.cat((embedding[0], attn_applied[0]), 1).unsqueeze(0)\n",
        "\n",
        "            if self.verbose:\n",
        "                print('Attn LC', attn_applied.shape)\n",
        "                print('Decoder input', decoder_input.shape)\n",
        "\n",
        "            out, decoder_state = self.decoder_rnn_cell(decoder_input, decoder_state)\n",
        "\n",
        "            if self.verbose:\n",
        "                print('Decoder intermediate output', out.shape)\n",
        "\n",
        "            out = self.h2o(decoder_state)\n",
        "            out = self.softmax(out)\n",
        "            outputs.append(out.view(1, -1))\n",
        "\n",
        "            if self.verbose:\n",
        "                print('Decoder output', out.shape)\n",
        "                self.verbose = False\n",
        "\n",
        "            max_idx = torch.argmax(out, 2, keepdim=True)\n",
        "            if not ground_truth is None:\n",
        "                max_idx = ground_truth[i].reshape(1, 1, 1)\n",
        "            one_hot = torch.zeros(out.shape, device=device)\n",
        "            one_hot.scatter_(2, max_idx, 1)\n",
        "\n",
        "            decoder_input = one_hot.detach()\n",
        "\n",
        "        return outputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cn4meWSMH3-W"
      },
      "source": [
        "net_attn = Transliteration_EncoderDecoder_Attention(len(eng_alpha2index), 256, len(hindi_alpha2index), verbose=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rdx161RSH6Sh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "9e08072c-3a10-4399-e549-86a4506abb6e"
      },
      "source": [
        "out = infer(net_attn, 'INDIA', 30)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Encoder output torch.Size([6, 256])\n",
            "Decoder state torch.Size([1, 1, 256])\n",
            "Decoder intermediate input torch.Size([1, 1, 129])\n",
            "U * Encoder output torch.Size([6, 256])\n",
            "W * Decoder state torch.Size([6, 256])\n",
            "V torch.Size([6, 1])\n",
            "Attn torch.Size([1, 6])\n",
            "Attn LC torch.Size([1, 1, 256])\n",
            "Decoder input torch.Size([1, 1, 512])\n",
            "Decoder intermediate output torch.Size([1, 1, 256])\n",
            "Decoder output torch.Size([1, 1, 129])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TOUIReq5H756",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        },
        "outputId": "95c105d6-71bd-45f4-958d-3e9eb90220a3"
      },
      "source": [
        "print(len(out))\n",
        "for i in range(len(out)):\n",
        "    print(out[i].shape, list(hindi_alpha2index.keys())[list(hindi_alpha2index.values()).index(torch.argmax(out[i]))])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "30\n",
            "torch.Size([1, 129]) ॑\n",
            "torch.Size([1, 129]) ु\n",
            "torch.Size([1, 129]) ॑\n",
            "torch.Size([1, 129]) ड़\n",
            "torch.Size([1, 129]) ॑\n",
            "torch.Size([1, 129]) ु\n",
            "torch.Size([1, 129]) ॑\n",
            "torch.Size([1, 129]) ु\n",
            "torch.Size([1, 129]) ॑\n",
            "torch.Size([1, 129]) ड़\n",
            "torch.Size([1, 129]) ॑\n",
            "torch.Size([1, 129]) ु\n",
            "torch.Size([1, 129]) ॑\n",
            "torch.Size([1, 129]) ु\n",
            "torch.Size([1, 129]) ॑\n",
            "torch.Size([1, 129]) ु\n",
            "torch.Size([1, 129]) ॑\n",
            "torch.Size([1, 129]) ड़\n",
            "torch.Size([1, 129]) ॑\n",
            "torch.Size([1, 129]) ु\n",
            "torch.Size([1, 129]) ॑\n",
            "torch.Size([1, 129]) ु\n",
            "torch.Size([1, 129]) ॑\n",
            "torch.Size([1, 129]) ु\n",
            "torch.Size([1, 129]) ॑\n",
            "torch.Size([1, 129]) ड़\n",
            "torch.Size([1, 129]) ॑\n",
            "torch.Size([1, 129]) ु\n",
            "torch.Size([1, 129]) ॑\n",
            "torch.Size([1, 129]) ु\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VsWcfO6sH96j"
      },
      "source": [
        "def train_batch(net, opt, criterion, batch_size, device = 'cpu', teacher_force = False):\n",
        "\n",
        "    net.train().to(device)\n",
        "    opt.zero_grad()\n",
        "    eng_batch, hindi_batch = train_data.get_batch(batch_size)\n",
        "\n",
        "    total_loss = 0\n",
        "    for i in range(batch_size):\n",
        "\n",
        "        input = word_rep(eng_batch[i], eng_alpha2index, device)\n",
        "        gt = gt_rep(hindi_batch[i], hindi_alpha2index, device)\n",
        "        outputs = net(input, gt.shape[0], device, ground_truth = gt if teacher_force else None)\n",
        "\n",
        "        for index, output in enumerate(outputs):\n",
        "            loss = criterion(output, gt[index]) / batch_size\n",
        "            loss.backward(retain_graph = True)\n",
        "            total_loss += loss\n",
        "\n",
        "    opt.step()\n",
        "    return total_loss/batch_size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "we13uN0FH_4d"
      },
      "source": [
        "def train_setup(net, lr = 0.01, n_batches = 100, batch_size = 10, momentum = 0.9, display_freq=5, device = 'cpu'):\n",
        "\n",
        "    net = net.to(device)\n",
        "    criterion = nn.NLLLoss(ignore_index = -1)\n",
        "    opt = optim.Adam(net.parameters(), lr=lr)\n",
        "    teacher_force_upto = n_batches//3\n",
        "\n",
        "    loss_arr = np.zeros(n_batches + 1)\n",
        "\n",
        "    for i in range(n_batches):\n",
        "        loss_arr[i+1] = (loss_arr[i]*i + train_batch(net, opt, criterion, batch_size, device = device, teacher_force = i<teacher_force_upto ))/(i + 1)\n",
        "\n",
        "        if i%display_freq == display_freq-1:\n",
        "            clear_output(wait=True)\n",
        "\n",
        "            print('Iteration', i, 'Loss', loss_arr[i])\n",
        "            plt.figure()\n",
        "            plt.plot(loss_arr[1:i], '-*')\n",
        "            plt.xlabel('Iteration')\n",
        "            plt.ylabel('Loss')\n",
        "            plt.show()\n",
        "            print('\\n\\n')\n",
        "\n",
        "    torch.save(net, 'model.pt')\n",
        "    return loss_arr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6tt6xxVkIBnR"
      },
      "source": [
        "net = Transliteration_EncoderDecoder(len(eng_alpha2index), 256, len(hindi_alpha2index))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xe9hTJB9IDZY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 588
        },
        "outputId": "646b4745-af68-466c-f440-8c2891283561"
      },
      "source": [
        "train_setup(net, lr=0.001, n_batches=20, batch_size = 64, display_freq=10, device = device_gpu)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration 19 Loss 0.4368971288204193\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAEGCAYAAACZ0MnKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Transliteration_EncoderDecoder. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type GRU. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Linear. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type LogSoftmax. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.        , 0.51884991, 0.51033264, 0.50913215, 0.5087682 ,\n",
              "       0.50566435, 0.49969694, 0.4981674 , 0.49658471, 0.49375948,\n",
              "       0.49325782, 0.48711652, 0.48135352, 0.47635835, 0.46657306,\n",
              "       0.45846862, 0.45051995, 0.44659132, 0.4413003 , 0.43689713,\n",
              "       0.43392131])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wgv0NYAoIGL2"
      },
      "source": [
        "net_att = Transliteration_EncoderDecoder_Attention(len(eng_alpha2index), 256, len(hindi_alpha2index))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g2q8AnHGIJNg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        },
        "outputId": "a7850517-f77a-4e8d-f86a-13904ab8861a"
      },
      "source": [
        "loss_history = train_setup(net_att, lr=0.001, n_batches=20, batch_size = 64, display_freq=10, device = device_gpu)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration 19 Loss 0.40468353033065796\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAEGCAYAAACZ0MnKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n17L2sF7oAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Transliteration_EncoderDecoder_Attention. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type GRU. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Linear. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type LogSoftmax. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wybHAdBPILjd"
      },
      "source": [
        "def test(net, word, device = 'cpu'):\n",
        "    net = net.eval().to(device)\n",
        "    outputs = infer(net, word, 30, device)\n",
        "    hindi_output = ''\n",
        "    for out in outputs:\n",
        "        val, indices = out.topk(1)\n",
        "        print(out)\n",
        "        index = indices.tolist()[0][0]\n",
        "        if index == 0:\n",
        "            break\n",
        "        hindi_char = hindi_alphabets[index+1]\n",
        "        hindi_output += hindi_char\n",
        "    print(word + ' - ' + hindi_output)\n",
        "    return hindi_output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WYyQh8pZIUH4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "eaf7b1a4-90e8-48f4-c408-915f94b0a0d1"
      },
      "source": [
        "test(net_att,'INDIA',device_gpu)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-3.5989, -6.8576, -6.1601, -3.9112, -6.7483, -7.0905, -4.5433, -5.4521,\n",
            "         -5.3864, -6.7204, -5.4626, -6.7828, -6.8841, -6.4949, -7.2466, -6.8093,\n",
            "         -5.1612, -6.6658, -6.0752, -6.8411, -5.9853, -6.8719, -3.1693, -5.5889,\n",
            "         -3.8552, -6.5747, -7.0595, -4.7725, -6.4522, -3.8014, -6.9068, -6.5365,\n",
            "         -3.8631, -6.7563, -3.9587, -7.0677, -5.1881, -3.9286, -5.3940, -3.6808,\n",
            "         -5.3624, -3.3540, -6.6408, -3.7861, -4.0813, -3.4818, -5.7994, -3.3678,\n",
            "         -4.0349, -3.0054, -6.9862, -3.5316, -6.9885, -6.9479, -3.6039, -4.0527,\n",
            "         -5.6834, -3.4049, -3.6810, -6.9253, -6.7911, -5.0708, -6.7100, -3.0983,\n",
            "         -3.1675, -3.6588, -3.8677, -4.5708, -6.0522, -7.1741, -6.4008, -6.4039,\n",
            "         -3.4750, -4.3746, -4.2326, -7.0532, -3.8124, -6.2278, -3.0917, -6.8739,\n",
            "         -7.0766, -6.3092, -6.9563, -6.7806, -6.7085, -6.7011, -6.7377, -6.9173,\n",
            "         -6.9576, -6.3676, -6.5895, -6.9851, -5.5497, -6.2091, -6.7071, -6.7825,\n",
            "         -6.8616, -6.9170, -6.6505, -6.7884, -6.8033, -6.7060, -6.7175, -6.7168,\n",
            "         -7.0756, -6.6420, -6.8932, -7.0804, -6.6719, -7.1195, -7.2852, -7.1731,\n",
            "         -6.4507, -6.8165, -7.0698, -6.8018, -6.9142, -6.9013, -6.7881, -6.9192,\n",
            "         -6.5544, -6.5852, -7.1016, -6.9302, -6.7718, -6.9290, -6.9399, -6.7999,\n",
            "         -7.0526]], device='cuda:0', grad_fn=<ViewBackward>)\n",
            "tensor([[-2.9173, -8.8170, -7.5806, -3.8164, -8.3234, -8.8692, -5.6431, -6.4898,\n",
            "         -6.4060, -8.2718, -6.5156, -8.6834, -8.5833, -7.9660, -9.2569, -8.5849,\n",
            "         -6.2895, -8.3995, -7.5933, -8.6451, -7.2906, -8.8193, -3.1732, -6.7590,\n",
            "         -4.0038, -8.2976, -9.0874, -5.4263, -7.9482, -3.9428, -8.5338, -8.1608,\n",
            "         -3.9261, -8.3845, -3.9488, -8.8928, -5.8942, -3.9431, -6.0814, -3.7417,\n",
            "         -6.3674, -3.0902, -8.3511, -4.1470, -4.4485, -3.8208, -7.1575, -3.3512,\n",
            "         -3.8224, -2.6132, -8.8509, -3.3735, -8.7794, -8.8330, -3.7309, -4.3480,\n",
            "         -6.7890, -3.4038, -3.7714, -8.5694, -8.4218, -5.6214, -8.4561, -2.5182,\n",
            "         -2.8455, -3.3761, -3.8493, -4.8868, -7.2775, -9.1024, -7.9698, -8.0303,\n",
            "         -3.2009, -4.5293, -4.4901, -8.9917, -3.8814, -7.6592, -2.5771, -8.6264,\n",
            "         -9.1202, -7.7281, -8.5851, -8.5426, -8.4035, -8.2199, -8.2348, -8.5320,\n",
            "         -8.6741, -8.0152, -8.3300, -8.7796, -6.3595, -7.4893, -8.2894, -8.4824,\n",
            "         -8.4557, -8.7544, -8.2346, -8.5722, -8.6749, -8.4814, -8.4981, -8.3542,\n",
            "         -8.9388, -8.2658, -8.5067, -8.9935, -8.3429, -8.9964, -9.1329, -9.0121,\n",
            "         -8.1425, -8.5682, -8.9120, -8.4931, -8.7693, -8.7169, -8.4036, -8.7466,\n",
            "         -8.1189, -8.3246, -8.9707, -8.8097, -8.5940, -8.8512, -8.7208, -8.5509,\n",
            "         -8.9115]], device='cuda:0', grad_fn=<ViewBackward>)\n",
            "tensor([[ -2.4594,  -9.6938,  -8.2282,  -3.8457,  -9.0175,  -9.6389,  -6.1866,\n",
            "          -6.9128,  -6.8047,  -8.8928,  -7.0381,  -9.5701,  -9.2589,  -8.6201,\n",
            "         -10.1623,  -9.3785,  -6.8191,  -9.2251,  -8.2567,  -9.4448,  -7.8434,\n",
            "          -9.6672,  -3.2652,  -7.3504,  -4.1140,  -9.0704,  -9.9729,  -5.7773,\n",
            "          -8.6205,  -4.0585,  -9.1987,  -8.9100,  -4.0191,  -9.0421,  -3.9503,\n",
            "          -9.6111,  -6.2414,  -4.0032,  -6.3090,  -3.8273,  -6.7995,  -3.0310,\n",
            "          -9.1468,  -4.3838,  -4.6955,  -4.0341,  -7.7964,  -3.4544,  -3.7016,\n",
            "          -2.6155,  -9.6803,  -3.3835,  -9.5808,  -9.6636,  -3.8320,  -4.5757,\n",
            "          -7.2369,  -3.4529,  -3.8988,  -9.2857,  -9.1334,  -5.8144,  -9.2582,\n",
            "          -2.3488,  -2.8106,  -3.2329,  -3.9348,  -5.0273,  -7.8310,  -9.9220,\n",
            "          -8.7519,  -8.7724,  -3.2005,  -4.6813,  -4.6770,  -9.8009,  -3.9661,\n",
            "          -8.3333,  -2.5203,  -9.3827, -10.0052,  -8.3776,  -9.2008,  -9.3065,\n",
            "          -9.0998,  -8.8489,  -8.8477,  -9.2289,  -9.3751,  -8.7240,  -9.1089,\n",
            "          -9.5398,  -6.6901,  -8.0499,  -9.0412,  -9.2723,  -9.1029,  -9.5684,\n",
            "          -8.9907,  -9.4159,  -9.5141,  -9.2304,  -9.2837,  -9.0989,  -9.7480,\n",
            "          -8.9541,  -9.1344,  -9.8265,  -9.1431,  -9.8320,  -9.9040,  -9.7890,\n",
            "          -8.9817,  -9.3629,  -9.7239,  -9.2119,  -9.5698,  -9.5143,  -9.0583,\n",
            "          -9.5359,  -8.8040,  -9.1174,  -9.8064,  -9.6430,  -9.3977,  -9.7137,\n",
            "          -9.4958,  -9.2756,  -9.6687]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward>)\n",
            "tensor([[ -2.2035, -10.0493,  -8.5105,  -3.8892,  -9.2977,  -9.9532,  -6.4191,\n",
            "          -7.0720,  -6.9413,  -9.1328,  -7.2710,  -9.9440,  -9.5145,  -8.8981,\n",
            "         -10.5353,  -9.6900,  -7.0299,  -9.5861,  -8.5263,  -9.7801,  -8.0609,\n",
            "         -10.0243,  -3.3270,  -7.6008,  -4.1508,  -9.4010, -10.3231,  -5.9221,\n",
            "          -8.9040,  -4.1155,  -9.4511,  -9.2432,  -4.0741,  -9.3001,  -3.9331,\n",
            "          -9.8625,  -6.4042,  -4.0264,  -6.3792,  -3.8648,  -6.9572,  -3.0387,\n",
            "          -9.4824,  -4.4985,  -4.8177,  -4.1205,  -8.0745,  -3.5145,  -3.6427,\n",
            "          -2.6820, -10.0254,  -3.4152,  -9.9220, -10.0047,  -3.8806,  -4.6995,\n",
            "          -7.3893,  -3.4770,  -3.9729,  -9.5682,  -9.4239,  -5.8815,  -9.5909,\n",
            "          -2.2867,  -2.8179,  -3.1470,  -3.9873,  -5.0905,  -8.0461, -10.2469,\n",
            "          -9.1135,  -9.0830,  -3.2352,  -4.7853,  -4.7600, -10.1324,  -4.0140,\n",
            "          -8.6078,  -2.5497,  -9.6933, -10.3657,  -8.6602,  -9.4050,  -9.6140,\n",
            "          -9.3581,  -9.0750,  -9.0915,  -9.5137,  -9.6257,  -9.0070,  -9.4424,\n",
            "          -9.8413,  -6.8232,  -8.2617,  -9.3629,  -9.6112,  -9.3584,  -9.9051,\n",
            "          -9.3170,  -9.7811,  -9.8509,  -9.5271,  -9.6167,  -9.4229, -10.0679,\n",
            "          -9.2280,  -9.3754, -10.1563,  -9.4958, -10.1744, -10.2001, -10.0921,\n",
            "          -9.3448,  -9.6933, -10.0455,  -9.4907,  -9.9004,  -9.8374,  -9.3067,\n",
            "          -9.8425,  -9.0629,  -9.4465, -10.1716,  -9.9762,  -9.7200, -10.0613,\n",
            "          -9.8085,  -9.5447,  -9.9662]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward>)\n",
            "INDIA - लीी\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'लीी'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-cvyedcINWE"
      },
      "source": [
        "def calc_accuracy(net, device = 'cpu'):\n",
        "    net = net.eval().to(device)\n",
        "    predictions = []\n",
        "    accuracy = 0\n",
        "    for i in range(len(test_data)):\n",
        "        eng, hindi = test_data[i]\n",
        "        gt = gt_rep(hindi, hindi_alpha2index, device)\n",
        "        outputs = infer(net, eng, gt.shape[0], device)\n",
        "        correct = 0\n",
        "        for index, out in enumerate(outputs):\n",
        "            val, indices = out.topk(1)\n",
        "            hindi_pos = indices.tolist()[0]\n",
        "            if hindi_pos[0] == gt[index][0]:\n",
        "                correct += 1\n",
        "\n",
        "        accuracy += correct/gt.shape[0]\n",
        "    accuracy /= len(test_data)\n",
        "    return accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jhPVtdqSIOuL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "fa03112a-a940-415d-c39e-9a843760e001"
      },
      "source": [
        "accuracy = calc_accuracy(net) * 100\n",
        "accuracy_attn = calc_accuracy(net_att) * 100\n",
        "print('Accuracy w/o attention ', accuracy)\n",
        "print('Acurracy with attention', accuracy_attn)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy w/o attention  20.561708291708243\n",
            "Acurracy with attention 18.525741480741456\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U6FYAh-0InMi"
      },
      "source": [
        "new_net=torch.load('/content/model_full_teacher_force.pt')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}